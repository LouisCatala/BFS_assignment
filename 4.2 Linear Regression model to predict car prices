import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Load the data
data = pd.read_csv(r'C:\Users\13473\Downloads\car_data.csv')

# Selecting 'Present_Price' as the feature and 'Selling_Price' as the target
X = data[['Present_Price']].values  # .values to get numpy array
y = data['Selling_Price'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the linear regression function (forward propagation)
def forward_propagation(X, parameters):
    m = parameters['m']
    c = parameters['c']
    predictions = np.multiply(m, X) + c
    return predictions

# Define the cost function (Mean Squared Error)
def cost_function(predictions, y):
    cost = np.mean((y - predictions) ** 2) * 0.5
    return cost

# Backward propagation to compute gradients
def backward_propagation(X, y, predictions):
    derivatives = dict()
    df = (y - predictions) * -1
    dm = np.mean(np.multiply(X, df))
    dc = np.mean(df)
    derivatives['dm'] = dm
    derivatives['dc'] = dc
    return derivatives

# Update the parameters 'm' and 'c' using the gradients
def update_parameters(parameters, derivatives, learning_rate):
    parameters['m'] -= learning_rate * derivatives['dm']
    parameters['c'] -= learning_rate * derivatives['dc']
    return parameters

# Train the model
def train(X_train, y_train, learning_rate, iters):
    parameters = {'m': np.random.uniform(0, 1) * -1, 'c': np.random.uniform(0, 1) * -1}
    loss = []
    for i in range(iters):
        predictions = forward_propagation(X_train, parameters)
        cost = cost_function(predictions, y_train)
        derivatives = backward_propagation(X_train, y_train, predictions)
        parameters = update_parameters(parameters, derivatives, learning_rate)
        loss.append(cost)
        print("Iteration = {}, Loss = {}".format(i+1, cost))
    return parameters, loss

# Train the model with the training data
parameters, loss = train(X_train, y_train, 0.001, 20)

# Make predictions on the test data
test_predictions = forward_propagation(X_test, parameters)
test_cost = cost_function(test_predictions, y_test)
print("Final cost on test data:", test_cost)

# Plot the regression line with actual test data points
plt.scatter(X_test, y_test, color='blue', label='Actual values')
plt.plot(X_test, test_predictions, color='orange', label='Predicted values')
plt.xlabel('Test Input (Present Price)')
plt.ylabel('Test Output (Selling Price)')
plt.legend()
plt.show()
